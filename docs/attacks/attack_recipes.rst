Attack Recipes
===============

We provide a number of pre-built attack recipes. To run an attack recipe, run::

    textattack attack --recipe [recipe_name]
    
Alzantot (Generating Natural Language Adversarial Examples)
###########

.. automodule:: textattack.attack_recipes.alzantot_2018
   :members:
   
BAE (BAE: BERT-Based Adversarial Examples)
############

.. automodule:: textattack.attack_recipes.deepwordbug_gao_2018

BERT-Attack: (BERT-Attack: Adversarial Attack Against BERT Using BERT
############

.. automodule:: textattack.attack_recipes.deepwordbug_gao_2018

DeepWordBug (Black-box Generation of Adversarial Text Sequences to Evade Deep Learning Classifiers)
############

.. automodule:: textattack.attack_recipes.deepwordbug_gao_2018
   :members:

HotFlip (HotFlip: White-Box Adversarial Examples for Text Classification)
###########

.. automodule:: textattack.attack_recipes.input_reduction_feng_2018
   :members:

Kuleshov (Adversarial Examples for Natural Language Classification Problems)
###########

.. automodule:: textattack.attack_recipes.kuleshov_2017
   :members:

Seq2Sick (Seq2Sick: Evaluating the Robustness of Sequence-to-Sequence Models with Adversarial Examples)
###########

.. automodule:: textattack.attack_recipes.seq2sick_cheng_2018_blackbox
   :members:


TextFooler (Is BERT Really Robust? A Strong Baseline for Natural Language Attack on Text Classification and Entailment)
###########

.. automodule:: textattack.attack_recipes.textfooler_jin_2019
   :members:


TextBugger (TextBugger: Generating Adversarial Text Against Real-world Applications)
###########

.. automodule:: textattack.attack_recipes.textbugger_li_2018
   :members:
